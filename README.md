# Cross-Document Conflict Detector

A GraphRAG-based Due Diligence tool for Private Equity/M&A sector that identifies logical contradictions across financial/legal documents.

## ğŸ¯ The Problem

In M&A due diligence, analysts spend days manually comparing hundreds of documents to find inconsistencies:
- "Document A says CEO gets **5% equity**"
- "Document B says CEO gets **3% equity**"

Standard LLMs miss these because they process documents separately. **We solve this.**

## ğŸ—ï¸ Architecture

```
Layer 1: Ingestion Engine (The Moat)
â”œâ”€â”€ LlamaParse â†’ Table-aware PDF parsing
â”œâ”€â”€ Semantic Chunking â†’ Preserve clause boundaries
â””â”€â”€ Metadata Extraction â†’ Page numbers, sections

Layer 2: Knowledge Layer (GraphRAG)
â”œâ”€â”€ Vector Store (ChromaDB) â†’ Semantic search
â”œâ”€â”€ Graph Store (NetworkX) â†’ Entity relationships
â””â”€â”€ Entity Extraction â†’ Structured data from text

Layer 3: Logic Agents
â”œâ”€â”€ Comparator â†’ Detect value mismatches
â””â”€â”€ Judge â†’ Verify and prevent hallucinations

Layer 4: Interface
â”œâ”€â”€ FastAPI Backend
â””â”€â”€ Streamlit UI (coming soon)
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- [Ollama](https://ollama.ai/) (for local LLM) or OpenAI API key
- [LlamaParse API key](https://cloud.llamaindex.ai/) (for table extraction)

### Installation

```bash
# Clone and setup
cd project-F
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys
```

### Run the API

```bash
uvicorn app.main:app --reload
```

### Local LLM Setup (Privacy Mode)

```bash
# Install Ollama and pull Llama 3
ollama pull llama3

# Set in .env
LLM_BACKEND=ollama
OLLAMA_MODEL=llama3
```

## ğŸ“ Project Structure

```
project-F/
â”œâ”€â”€ app/                 # FastAPI application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/      # PDF parsing & chunking
â”‚   â”œâ”€â”€ knowledge/      # Vector & Graph stores
â”‚   â”œâ”€â”€ agents/         # Conflict detection logic
â”‚   â””â”€â”€ utils/          # LLM factory, logging
â”œâ”€â”€ tests/              # Test suite
â”œâ”€â”€ data/               # Uploads, processed files, graphs
â””â”€â”€ scripts/            # CLI utilities
```

## ğŸ”’ Privacy First

The system is designed for on-premise deployment:
- Swap LLM backend in one line of config
- Local embeddings with HuggingFace models
- All data stays on your infrastructure

## ğŸ“„ License

MIT
